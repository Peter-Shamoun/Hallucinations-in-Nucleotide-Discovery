{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI  #OpenAI API client\n",
    "from dotenv import load_dotenv  #For loading environment variables from .env file\n",
    "load_dotenv()  #This loads variables from a .env file into environment variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  #Get the OpenAI API key from environment variables\n",
    "client = OpenAI(api_key=api_key)  #Initialize the OpenAI client with the API key\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored enhancer with 98 genes.\n",
      "Stored methylated with 100 genes.\n",
      "Stored non_enhancer with 98 genes.\n",
      "Stored non_methylated with 100 genes.\n",
      "Stored non_promoter with 100 genes.\n",
      "Stored non_protein_coding with 88 genes.\n",
      "Stored non_splice_site with 70 genes.\n",
      "Stored promoter with 100 genes.\n",
      "Stored protein_coding with 100 genes.\n",
      "Stored splice_site with 70 genes.\n"
     ]
    }
   ],
   "source": [
    "fasta_dir = \"sequences\"\n",
    "\n",
    "# Mapping of base categories to questions\n",
    "questions = {\n",
    "    \"protein_coding\": \"Does this nucleotide sequence encode a protein? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"enhancer\": \"Does this nucleotide sequence function as an enhancer in gene regulation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"promoter\": \"Does this nucleotide sequence act as a promoter for transcription initiation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"splice_site\": \"Does this nucleotide sequence contain a splice site for RNA processing? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"methylated\": \"Is this nucleotide sequence methylated as part of epigenetic regulation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\"\n",
    "}\n",
    "\n",
    "# Dictionary to hold sequence data\n",
    "sequence_arrays = {}\n",
    "\n",
    "# Loop through all FASTA files in the directory\n",
    "for file in os.listdir(fasta_dir):\n",
    "    if file.endswith(\".fasta\"):  # Process only FASTA files\n",
    "        file_path = os.path.join(fasta_dir, file)\n",
    "        var_name = os.path.splitext(file)[0]  # Use file name (without extension) as key\n",
    "\n",
    "        # Determine base category\n",
    "        if var_name.startswith(\"non_\"):\n",
    "            base_category = var_name[4:]  # Remove \"non_\" prefix\n",
    "        else:\n",
    "            base_category = var_name\n",
    "        question = questions[base_category]  # Get the corresponding question\n",
    "\n",
    "        # Read the FASTA file and create a list of dictionaries\n",
    "        gene_dicts = []\n",
    "        for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "            gene_dict = {\n",
    "                \"file_name\": var_name,\n",
    "                \"gene\": str(record.seq),\n",
    "                \"question\": question,  # Add the question key\n",
    "            }\n",
    "            gene_dicts.append(gene_dict)\n",
    "        \n",
    "        # Store the list of dictionaries in the dictionary\n",
    "        sequence_arrays[var_name] = gene_dicts\n",
    "\n",
    "        print(f\"Stored {var_name} with {len(gene_dicts)} genes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hallucination(gene_dict, model):\n",
    "    response = client.chat.completions.create(\n",
    "            model= model,  #Use the model specified in the constructor\n",
    "\n",
    "            messages=\n",
    "            [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} Describe the gene in natural language:\"}\n",
    "        ],  #The conversation context to send to the API\n",
    "\n",
    "\n",
    "            max_tokens=256,  #Maximum length of the response\n",
    "\n",
    "            temperature=0.6  #Controls randomness/creativity of the response\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification(gene_dict, model):\n",
    "    response = client.chat.completions.create(\n",
    "            model = model,  #Use the model specified in the constructor\n",
    "\n",
    "            messages=\n",
    "            [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} {gene_dict['question']}\"}\n",
    "        ],  #The conversation context to send to the API\n",
    "\n",
    "\n",
    "            max_tokens=256,  #Maximum length of the response\n",
    "\n",
    "            temperature=0.6  #Controls randomness/creativity of the response\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hallucination_classification(gene_dict, model):\n",
    "    response = client.chat.completions.create(\n",
    "            model = model,  #Use the model specified in the constructor\n",
    "\n",
    "            messages=\n",
    "            [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} {gene_dict['hallucination']} {gene_dict['question']}\"}\n",
    "        ],  #The conversation context to send to the API\n",
    "\n",
    "\n",
    "            max_tokens=256,  #Maximum length of the response\n",
    "\n",
    "            temperature=0.6  #Controls randomness/creativity of the response\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model [1/6]: gpt-3.5-turbo:   0%|          | 0/10 [00:20<?, ?it/s]\n",
      "                                                                                  \n",
      "                                                                                         \n",
      "                                                                                      \n",
      "                                                                                            \n",
      "                                                                                          \n",
      "                                                                                            \n",
      "                                                                                         \n",
      "                                                                                      \n",
      "                                                                                            \n",
      "                                                                                      \n",
      "Model [1/6]: gpt-3.5-turbo: 100%|██████████| 10/10 [45:19<00:00, 271.94s/it]\n",
      "Model [2/6]: gpt-4o-mini: 100%|██████████| 10/10 [1:33:15<00:00, 559.59s/it]\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "MODELS = [\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"gpt-4o-mini\",\n",
    "\n",
    "]\n",
    "for model_idx, model in enumerate(MODELS):\n",
    "    model_progress = tqdm(total=len(sequence_arrays), desc=f\"Model [{model_idx+1}/6]: {model.split('/')[-1]}\")\n",
    "    \n",
    "    for file_idx, (file, sequences) in enumerate(sequence_arrays.items()):\n",
    "        file_progress = tqdm(total=len(sequences), desc=f\"File [{file_idx+1}/{len(sequence_arrays)}]: {file}\", leave=False)\n",
    "        \n",
    "        for gene_idx, gene in enumerate(sequences):\n",
    "            file_progress.set_postfix_str(f\"Gene {gene_idx+1}/{len(sequences)}\")\n",
    "            \n",
    "            result = gene.copy()\n",
    "            result['model'] = model\n",
    "            \n",
    "            try:\n",
    "                result['hallucination'] = generate_hallucination(result, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating hallucination for {file}, gene {gene_idx+1}: {str(e)}\")\n",
    "                result['hallucination'] = None\n",
    "            \n",
    "            try:\n",
    "                result['hallucination_classification'] = generate_hallucination_classification(result, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating hallucination classification for {file}, gene {gene_idx+1}: {str(e)}\")\n",
    "                result['hallucination_classification'] = None\n",
    "            \n",
    "            try:\n",
    "                result['classification'] = generate_classification(result, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating classification for {file}, gene {gene_idx+1}: {str(e)}\")\n",
    "                result['classification'] = None\n",
    "            \n",
    "            all_results.append(result)\n",
    "            \n",
    "            file_progress.update(1)\n",
    "        \n",
    "        file_progress.close()\n",
    "        model_progress.update(1)\n",
    "    \n",
    "    model_progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results)\n",
    "df['correct'] = df['file_name'].str.contains(\"non\", case=True, na=False).map({True: \"No\", False: \"Yes\"})\n",
    "df['hallucination_classification'] = df['hallucination_classification'].str.replace(\".\", \"\", regex=False)\n",
    "df['classification'] = df['classification'].str.replace(\".\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'No' 'No' ... 'No' 'No' 'Yes']\n",
      "['No' 'No' 'No' ... 'No' 'Yes' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "df['hallucination_classification'] = df['hallucination_classification'].apply(\n",
    "    lambda x: 'Yes' if isinstance(x, str) and x.split()[0].lower()[:3] == 'yes' else\n",
    "              'No' if isinstance(x, str) and x.split()[0].lower()[:2] == 'no' else np.nan\n",
    ")\n",
    "print(df['hallucination_classification'].values)\n",
    "\n",
    "df['classification'] = df['classification'].apply(\n",
    "    lambda x: 'Yes' if isinstance(x, str) and x.split()[0].lower()[:3] == 'yes' else\n",
    "              'No' if isinstance(x, str) and x.split()[0].lower()[:2] == 'no' else np.nan\n",
    ")\n",
    "print(df['classification'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_name                       0\n",
       "gene                            0\n",
       "question                        0\n",
       "model                           0\n",
       "hallucination                   0\n",
       "hallucination_classification    1\n",
       "classification                  0\n",
       "correct                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df['hallucination_correct'] = df['hallucination_classification'] == df['correct']\n",
    "df['no_hallucination_correct'] = df['classification'] == df['correct']\n",
    "df.to_csv(\"trail_1_GPT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hallucination_correct</th>\n",
       "      <th>no_hallucination_correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.499458</td>\n",
       "      <td>0.486457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>0.474026</td>\n",
       "      <td>0.508658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               hallucination_correct  no_hallucination_correct\n",
       "model                                                         \n",
       "gpt-3.5-turbo               0.499458                  0.486457\n",
       "gpt-4o-mini                 0.474026                  0.508658"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results = df.groupby('model')[['hallucination_correct', 'no_hallucination_correct']].mean()\n",
    "grouped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>enhancer</th>\n",
       "      <th>promoter</th>\n",
       "      <th>splice_site</th>\n",
       "      <th>methylated</th>\n",
       "      <th>protein_coding</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>hallucination_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-3.5-turbo</th>\n",
       "      <th>Hallucination</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.512563</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.4973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Hallucination</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.552764</td>\n",
       "      <td>0.367021</td>\n",
       "      <td>0.4872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-4o-mini</th>\n",
       "      <th>Hallucination</th>\n",
       "      <td>0.494898</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.377660</td>\n",
       "      <td>0.4741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Hallucination</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.5092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature                             enhancer  promoter  splice_site  \\\n",
       "model         hallucination_status                                    \n",
       "gpt-3.5-turbo Hallucination         0.500000     0.485     0.457143   \n",
       "              No Hallucination      0.500000     0.495     0.521429   \n",
       "gpt-4o-mini   Hallucination         0.494898     0.505     0.492857   \n",
       "              No Hallucination      0.500000     0.500     0.514286   \n",
       "\n",
       "feature                             methylated  protein_coding     AVG  \n",
       "model         hallucination_status                                      \n",
       "gpt-3.5-turbo Hallucination           0.512563        0.531915  0.4973  \n",
       "              No Hallucination        0.552764        0.367021  0.4872  \n",
       "gpt-4o-mini   Hallucination           0.500000        0.377660  0.4741  \n",
       "              No Hallucination        0.500000        0.531915  0.5092  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancer_hallucination_correct = df[df['file_name'].str.contains(\"enhancer\")].groupby('model')['hallucination_correct'].mean()\n",
    "enhancer_no_hallucination_correct = df[df['file_name'].str.contains(\"enhancer\")].groupby('model')['no_hallucination_correct'].mean()\n",
    "\n",
    "promoter_hallucination_correct = df[df['file_name'].str.contains(\"promoter\")].groupby('model')['hallucination_correct'].mean()\n",
    "promoter_no_hallucination_correct = df[df['file_name'].str.contains(\"promoter\")].groupby('model')['no_hallucination_correct'].mean() \n",
    "\n",
    "splice_site_hallucination_correct = df[df['file_name'].str.contains(\"splice_site\")].groupby('model')['hallucination_correct'].mean()     \n",
    "splice_site_no_hallucination_correct = df[df['file_name'].str.contains(\"splice_site\")].groupby('model')['no_hallucination_correct'].mean()\n",
    "\n",
    "methylated_hallucination_correct = df[df['file_name'].str.contains(\"methylated\")].groupby('model')['hallucination_correct'].mean()   \n",
    "methylated_no_hallucination_correct = df[df['file_name'].str.contains(\"methylated\")].groupby('model')['no_hallucination_correct'].mean() \n",
    "\n",
    "protein_coding_hallucination_correct = df[df['file_name'].str.contains(\"protein_coding\")].groupby('model')['hallucination_correct'].mean()   \n",
    "protein_coding_no_hallucination_correct = df[df['file_name'].str.contains(\"protein_coding\")].groupby('model')['no_hallucination_correct'].mean()\n",
    "\n",
    "data = {\n",
    "    'enhancer_hallucination_correct': enhancer_hallucination_correct,\n",
    "    'enhancer_no_hallucination_correct': enhancer_no_hallucination_correct,\n",
    "    'promoter_hallucination_correct': promoter_hallucination_correct,\n",
    "    'promoter_no_hallucination_correct': promoter_no_hallucination_correct,\n",
    "    'splice_site_hallucination_correct': splice_site_hallucination_correct,\n",
    "    'splice_site_no_hallucination_correct': splice_site_no_hallucination_correct,\n",
    "    'methylated_hallucination_correct': methylated_hallucination_correct,\n",
    "    'methylated_no_hallucination_correct': methylated_no_hallucination_correct,\n",
    "    'protein_coding_hallucination_correct': protein_coding_hallucination_correct,\n",
    "    'protein_coding_no_hallucination_correct': protein_coding_no_hallucination_correct\n",
    "}\n",
    "\n",
    "pivot_data = []\n",
    "\n",
    "for feature in ['enhancer', 'promoter', 'splice_site', 'methylated', 'protein_coding']:\n",
    "    hall_series = data[f'{feature}_hallucination_correct']\n",
    "    \n",
    "    no_hall_series = data[f'{feature}_no_hallucination_correct']\n",
    "    \n",
    "    for model in hall_series.index:\n",
    "        pivot_data.append({\n",
    "            'model': model,\n",
    "            'hallucination_status': 'Hallucination',\n",
    "            'feature': feature,\n",
    "            'correct_count': hall_series[model]\n",
    "        })\n",
    "        \n",
    "        pivot_data.append({\n",
    "            'model': model,\n",
    "            'hallucination_status': 'No Hallucination',\n",
    "            'feature': feature,\n",
    "            'correct_count': no_hall_series[model]\n",
    "        })\n",
    "\n",
    "long_df = pd.DataFrame(pivot_data)\n",
    "\n",
    "pivot_df = long_df.pivot_table(\n",
    "    index=['model', 'hallucination_status'],\n",
    "    columns='feature',\n",
    "    values='correct_count'\n",
    ")\n",
    "\n",
    "feature_order = ['enhancer', 'promoter', 'splice_site', 'methylated', 'protein_coding']\n",
    "pivot_df = pivot_df[feature_order]\n",
    "\n",
    "\n",
    "pivot_df['AVG'] = pivot_df.mean(axis=1)\n",
    "\n",
    "pivot_df['AVG'] = pivot_df['AVG'].round(4) \n",
    "\n",
    "pivot_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
