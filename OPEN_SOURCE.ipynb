{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "load_dotenv()\n",
    "nvda = os.getenv(\"nvda\")\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = nvda\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored enhancer with 98 genes.\n",
      "Stored methylated with 100 genes.\n",
      "Stored non_enhancer with 98 genes.\n",
      "Stored non_methylated with 100 genes.\n",
      "Stored non_promoter with 100 genes.\n",
      "Stored non_protein_coding with 88 genes.\n",
      "Stored non_splice_site with 70 genes.\n",
      "Stored promoter with 100 genes.\n",
      "Stored protein_coding with 100 genes.\n",
      "Stored splice_site with 70 genes.\n"
     ]
    }
   ],
   "source": [
    "fasta_dir = \"sequences\"\n",
    "\n",
    "# Mapping of base categories to questions\n",
    "questions = {\n",
    "    \"protein_coding\": \"Does this nucleotide sequence encode a protein? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"enhancer\": \"Does this nucleotide sequence function as an enhancer in gene regulation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"promoter\": \"Does this nucleotide sequence act as a promoter for transcription initiation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"splice_site\": \"Does this nucleotide sequence contain a splice site for RNA processing? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"methylated\": \"Is this nucleotide sequence methylated as part of epigenetic regulation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\"\n",
    "}\n",
    "\n",
    "# Dictionary to hold sequence data\n",
    "sequence_arrays = {}\n",
    "\n",
    "# Loop through all FASTA files in the directory\n",
    "for file in os.listdir(fasta_dir):\n",
    "    if file.endswith(\".fasta\"):  # Process only FASTA files\n",
    "        file_path = os.path.join(fasta_dir, file)\n",
    "        var_name = os.path.splitext(file)[0]  # Use file name (without extension) as key\n",
    "\n",
    "        # Determine base category\n",
    "        if var_name.startswith(\"non_\"):\n",
    "            base_category = var_name[4:]  # Remove \"non_\" prefix\n",
    "        else:\n",
    "            base_category = var_name\n",
    "        question = questions[base_category]  # Get the corresponding question\n",
    "\n",
    "        # Read the FASTA file and create a list of dictionaries\n",
    "        gene_dicts = []\n",
    "        for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "            gene_dict = {\n",
    "                \"file_name\": var_name,\n",
    "                \"gene\": str(record.seq),\n",
    "                \"question\": question,  # Add the question key\n",
    "            }\n",
    "            gene_dicts.append(gene_dict)\n",
    "        \n",
    "        # Store the list of dictionaries in the dictionary\n",
    "        sequence_arrays[var_name] = gene_dicts\n",
    "\n",
    "        print(f\"Stored {var_name} with {len(gene_dicts)} genes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hallucination(gene_dict, model):\n",
    "    \"\"\"Generate a hallucination description for a gene sequence\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} Describe the gene in natural language:\"}\n",
    "        ],\n",
    "        max_tokens=256,\n",
    "        temperature=0.6\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification(gene_dict, model):\n",
    "    \"\"\"Generate a classification (Yes/No) for a gene sequence\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} {gene_dict['question']}\"}\n",
    "        ],\n",
    "        max_tokens=256,\n",
    "        temperature=0.6\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hallucination_classification(gene_dict, model, hallucination):\n",
    "    \"\"\"Generate a classification with hallucination included\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} {hallucination} {gene_dict['question']}\"}\n",
    "        ],\n",
    "        max_tokens=256,\n",
    "        temperature=0.6\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hallucinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hallucinations for meta/llama3-8b-instruct: 100%|██████████| 10/10 [28:35<00:00, 171.58s/it]\n",
      "Hallucinations for meta/llama-3.1-8b-instruct: 100%|██████████| 10/10 [55:05<00:00, 330.50s/it]\n",
      "Hallucinations for meta/llama-3.3-70b-instruct: 100%|██████████| 10/10 [56:00<00:00, 336.04s/it]\n",
      "Hallucinations for tiiuae/falcon3-7b-instruct: 100%|██████████| 10/10 [53:15<00:00, 319.60s/it]\n",
      "Hallucinations for qwen/qwen2.5-7b-instruct: 100%|██████████| 10/10 [1:28:55<00:00, 533.51s/it]\n",
      "Hall: qwen/qwen2.5-7b-instruct / Class: qwen/qwen2.5-7b-instruct: 100%|██████████| 25/25 [4:09:49<00:00, 599.57s/it]        \n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "MODELS = [\n",
    "    \"meta/llama3-8b-instruct\",\n",
    "    \"meta/llama-3.1-8b-instruct\",\n",
    "    \"meta/llama-3.3-70b-instruct\",\n",
    "    \"tiiuae/falcon3-7b-instruct\",\n",
    "    \"qwen/qwen2.5-7b-instruct\",\n",
    "    ]\n",
    "\n",
    "# Dictionary to store hallucinations for reuse\n",
    "# Dictionary to store hallucinations for reuse\n",
    "hallucinations = {}\n",
    "\n",
    "# First, generate hallucinations with each model\n",
    "print(\"Generating hallucinations...\")\n",
    "for hallucination_model in MODELS:\n",
    "    hallucinations[hallucination_model] = {}\n",
    "    for file_name, sequences in tqdm(sequence_arrays.items(), desc=f\"Hallucinations for {hallucination_model}\"):\n",
    "        hallucinations[hallucination_model][file_name] = {}\n",
    "        for i, gene_dict in enumerate(sequences):\n",
    "            try:\n",
    "                hallucination = generate_hallucination(gene_dict, hallucination_model)\n",
    "                hallucinations[hallucination_model][file_name][i] = hallucination\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating hallucination for {file_name}, gene {i}: {str(e)}\")\n",
    "                hallucinations[hallucination_model][file_name][i] = None\n",
    "\n",
    "# Results will be stored here\n",
    "all_results = []\n",
    "\n",
    "# Now, for each combination of hallucination model and classification model\n",
    "progress = tqdm(total=len(MODELS) * len(MODELS))\n",
    "for hallucination_model in MODELS:\n",
    "    for classification_model in MODELS:\n",
    "        progress.set_description(f\"Hall: {hallucination_model} / Class: {classification_model}\")\n",
    "        \n",
    "        # For each file (category of sequences)\n",
    "        for file_name, sequences in sequence_arrays.items():\n",
    "            for i, gene_dict in enumerate(sequences):\n",
    "                result = gene_dict.copy()\n",
    "                \n",
    "                # Add model info\n",
    "                result['hallucination_model'] = hallucination_model\n",
    "                result['classification_model'] = classification_model\n",
    "                \n",
    "                # Get the pre-generated hallucination\n",
    "                hallucination = hallucinations[hallucination_model][file_name].get(i)\n",
    "                result['hallucination'] = hallucination\n",
    "                \n",
    "                # Skip if hallucination was not generated\n",
    "                if hallucination is None:\n",
    "                    continue\n",
    "                \n",
    "                # Generate direct classification (without hallucination)\n",
    "                try:\n",
    "                    result['classification'] = generate_classification(result, classification_model)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating classification: {str(e)}\")\n",
    "                    result['classification'] = None\n",
    "                \n",
    "                # Generate classification with hallucination\n",
    "                try:\n",
    "                    result['hallucination_classification'] = generate_hallucination_classification(\n",
    "                        result, classification_model, hallucination\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating hallucination classification: {str(e)}\")\n",
    "                    result['hallucination_classification'] = None\n",
    "                \n",
    "                all_results.append(result)\n",
    "        \n",
    "        progress.update(1)\n",
    "progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "df['correct'] = df['file_name'].str.contains(\"non\", case=True, na=False).map({True: \"No\", False: \"Yes\"})\n",
    "\n",
    "df['hallucination_classification'] = df['hallucination_classification'].str.replace(\".\", \"\", regex=False)\n",
    "df['classification'] = df['classification'].str.replace(\".\", \"\", regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'Yes' 'Yes' ... 'No' 'No' 'No']\n",
      "['No' 'No' 'No' ... 'No' 'No' 'No']\n"
     ]
    }
   ],
   "source": [
    "def classify_value(x):\n",
    "    if isinstance(x, str):\n",
    "        parts = x.split()\n",
    "        if parts:  # only process non-empty strings\n",
    "            first = parts[0].lower()\n",
    "            if first.startswith('yes'):\n",
    "                return 'Yes'\n",
    "            elif first.startswith('no'):\n",
    "                return 'No'\n",
    "    return np.nan\n",
    "\n",
    "df['hallucination_classification'] = df['hallucination_classification'].apply(classify_value)\n",
    "print(df['hallucination_classification'].values)\n",
    "\n",
    "df['classification'] = df['classification'].apply(classify_value)\n",
    "print(df['classification'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hallucination_model\n",
       "meta/llama-3.1-8b-instruct     6\n",
       "qwen/qwen2.5-7b-instruct       4\n",
       "meta/llama-3.3-70b-instruct    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['hallucination_classification'].isna()]['hallucination_model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hallucination_model\n",
       "meta/llama-3.3-70b-instruct    1\n",
       "qwen/qwen2.5-7b-instruct       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['classification'].isna()]['hallucination_model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16196\\AppData\\Local\\Temp\\ipykernel_4480\\1960844081.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['hallucination_correct'] = df['hallucination_classification'] == df['correct']\n",
      "C:\\Users\\16196\\AppData\\Local\\Temp\\ipykernel_4480\\1960844081.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['no_hallucination_correct'] = df['classification'] == df['correct']\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['hallucination_classification', 'classification', 'correct'])\n",
    "\n",
    "# Add correctness columns\n",
    "df['hallucination_correct'] = df['hallucination_classification'] == df['correct']\n",
    "df['no_hallucination_correct'] = df['classification'] == df['correct']\n",
    "\n",
    "# Save full results\n",
    "df.to_csv(\"cross_model_hallucination_OPEN_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results saved to CSV files.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hallucination_model</th>\n",
       "      <th>classification_model</th>\n",
       "      <th>combo</th>\n",
       "      <th>enhancer_hall_acc</th>\n",
       "      <th>enhancer_no_hall_acc</th>\n",
       "      <th>promoter_hall_acc</th>\n",
       "      <th>promoter_no_hall_acc</th>\n",
       "      <th>splice_site_hall_acc</th>\n",
       "      <th>splice_site_no_hall_acc</th>\n",
       "      <th>methylated_hall_acc</th>\n",
       "      <th>methylated_no_hall_acc</th>\n",
       "      <th>protein_coding_hall_acc</th>\n",
       "      <th>protein_coding_no_hall_acc</th>\n",
       "      <th>overall_hall_acc</th>\n",
       "      <th>overall_no_hall_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct-meta/llama3-8b-instruct</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.439394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct-meta/llama-3.1-8b-inst...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.558511</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.479437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct-meta/llama-3.3-70b-ins...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>0.505411</td>\n",
       "      <td>0.502165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct-tiiuae/falcon3-7b-inst...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.491342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct-qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.493506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct-meta/llama3-8b-inst...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.439394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct-meta/llama-3.1-8b-i...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.519565</td>\n",
       "      <td>0.479348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct-meta/llama-3.3-70b-...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>0.521645</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct-tiiuae/falcon3-7b-i...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622340</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.524946</td>\n",
       "      <td>0.491323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct-qwen/qwen2.5-7b-ins...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.521645</td>\n",
       "      <td>0.493506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct-meta/llama3-8b-ins...</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.510823</td>\n",
       "      <td>0.439394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct-meta/llama-3.1-8b-...</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>0.510101</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.478827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct-meta/llama-3.3-70b...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>0.504329</td>\n",
       "      <td>0.503247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct-tiiuae/falcon3-7b-...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.542553</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.510823</td>\n",
       "      <td>0.491342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct-qwen/qwen2.5-7b-in...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.493506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct-meta/llama3-8b-inst...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.439394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct-meta/llama-3.1-8b-i...</td>\n",
       "      <td>0.494898</td>\n",
       "      <td>0.505102</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.445887</td>\n",
       "      <td>0.480519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct-meta/llama-3.3-70b-...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>0.459957</td>\n",
       "      <td>0.501082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct-tiiuae/falcon3-7b-i...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.474026</td>\n",
       "      <td>0.491342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct-qwen/qwen2.5-7b-ins...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.478355</td>\n",
       "      <td>0.493506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>meta/llama3-8b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct-meta/llama3-8b-instruct</td>\n",
       "      <td>0.494898</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.439394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>meta/llama-3.1-8b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct-meta/llama-3.1-8b-ins...</td>\n",
       "      <td>0.525510</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.453237</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>0.545918</td>\n",
       "      <td>0.494898</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.486398</td>\n",
       "      <td>0.478781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>meta/llama-3.3-70b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct-meta/llama-3.3-70b-in...</td>\n",
       "      <td>0.494898</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.335106</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>0.466450</td>\n",
       "      <td>0.501082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>tiiuae/falcon3-7b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct-tiiuae/falcon3-7b-ins...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.478355</td>\n",
       "      <td>0.491342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>qwen/qwen2.5-7b-instruct-qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>0.494898</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.493506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hallucination_model         classification_model  \\\n",
       "0       meta/llama3-8b-instruct      meta/llama3-8b-instruct   \n",
       "1       meta/llama3-8b-instruct   meta/llama-3.1-8b-instruct   \n",
       "2       meta/llama3-8b-instruct  meta/llama-3.3-70b-instruct   \n",
       "3       meta/llama3-8b-instruct   tiiuae/falcon3-7b-instruct   \n",
       "4       meta/llama3-8b-instruct     qwen/qwen2.5-7b-instruct   \n",
       "5    meta/llama-3.1-8b-instruct      meta/llama3-8b-instruct   \n",
       "6    meta/llama-3.1-8b-instruct   meta/llama-3.1-8b-instruct   \n",
       "7    meta/llama-3.1-8b-instruct  meta/llama-3.3-70b-instruct   \n",
       "8    meta/llama-3.1-8b-instruct   tiiuae/falcon3-7b-instruct   \n",
       "9    meta/llama-3.1-8b-instruct     qwen/qwen2.5-7b-instruct   \n",
       "10  meta/llama-3.3-70b-instruct      meta/llama3-8b-instruct   \n",
       "11  meta/llama-3.3-70b-instruct   meta/llama-3.1-8b-instruct   \n",
       "12  meta/llama-3.3-70b-instruct  meta/llama-3.3-70b-instruct   \n",
       "13  meta/llama-3.3-70b-instruct   tiiuae/falcon3-7b-instruct   \n",
       "14  meta/llama-3.3-70b-instruct     qwen/qwen2.5-7b-instruct   \n",
       "15   tiiuae/falcon3-7b-instruct      meta/llama3-8b-instruct   \n",
       "16   tiiuae/falcon3-7b-instruct   meta/llama-3.1-8b-instruct   \n",
       "17   tiiuae/falcon3-7b-instruct  meta/llama-3.3-70b-instruct   \n",
       "18   tiiuae/falcon3-7b-instruct   tiiuae/falcon3-7b-instruct   \n",
       "19   tiiuae/falcon3-7b-instruct     qwen/qwen2.5-7b-instruct   \n",
       "20     qwen/qwen2.5-7b-instruct      meta/llama3-8b-instruct   \n",
       "21     qwen/qwen2.5-7b-instruct   meta/llama-3.1-8b-instruct   \n",
       "22     qwen/qwen2.5-7b-instruct  meta/llama-3.3-70b-instruct   \n",
       "23     qwen/qwen2.5-7b-instruct   tiiuae/falcon3-7b-instruct   \n",
       "24     qwen/qwen2.5-7b-instruct     qwen/qwen2.5-7b-instruct   \n",
       "\n",
       "                                                combo  enhancer_hall_acc  \\\n",
       "0     meta/llama3-8b-instruct-meta/llama3-8b-instruct           0.500000   \n",
       "1   meta/llama3-8b-instruct-meta/llama-3.1-8b-inst...           0.500000   \n",
       "2   meta/llama3-8b-instruct-meta/llama-3.3-70b-ins...           0.500000   \n",
       "3   meta/llama3-8b-instruct-tiiuae/falcon3-7b-inst...           0.500000   \n",
       "4    meta/llama3-8b-instruct-qwen/qwen2.5-7b-instruct           0.500000   \n",
       "5   meta/llama-3.1-8b-instruct-meta/llama3-8b-inst...           0.500000   \n",
       "6   meta/llama-3.1-8b-instruct-meta/llama-3.1-8b-i...           0.500000   \n",
       "7   meta/llama-3.1-8b-instruct-meta/llama-3.3-70b-...           0.500000   \n",
       "8   meta/llama-3.1-8b-instruct-tiiuae/falcon3-7b-i...           0.500000   \n",
       "9   meta/llama-3.1-8b-instruct-qwen/qwen2.5-7b-ins...           0.500000   \n",
       "10  meta/llama-3.3-70b-instruct-meta/llama3-8b-ins...           0.510204   \n",
       "11  meta/llama-3.3-70b-instruct-meta/llama-3.1-8b-...           0.489796   \n",
       "12  meta/llama-3.3-70b-instruct-meta/llama-3.3-70b...           0.500000   \n",
       "13  meta/llama-3.3-70b-instruct-tiiuae/falcon3-7b-...           0.500000   \n",
       "14  meta/llama-3.3-70b-instruct-qwen/qwen2.5-7b-in...           0.500000   \n",
       "15  tiiuae/falcon3-7b-instruct-meta/llama3-8b-inst...           0.500000   \n",
       "16  tiiuae/falcon3-7b-instruct-meta/llama-3.1-8b-i...           0.494898   \n",
       "17  tiiuae/falcon3-7b-instruct-meta/llama-3.3-70b-...           0.500000   \n",
       "18  tiiuae/falcon3-7b-instruct-tiiuae/falcon3-7b-i...           0.500000   \n",
       "19  tiiuae/falcon3-7b-instruct-qwen/qwen2.5-7b-ins...           0.500000   \n",
       "20   qwen/qwen2.5-7b-instruct-meta/llama3-8b-instruct           0.494898   \n",
       "21  qwen/qwen2.5-7b-instruct-meta/llama-3.1-8b-ins...           0.525510   \n",
       "22  qwen/qwen2.5-7b-instruct-meta/llama-3.3-70b-in...           0.494898   \n",
       "23  qwen/qwen2.5-7b-instruct-tiiuae/falcon3-7b-ins...           0.500000   \n",
       "24  qwen/qwen2.5-7b-instruct-qwen/qwen2.5-7b-instruct           0.494898   \n",
       "\n",
       "    enhancer_no_hall_acc  promoter_hall_acc  promoter_no_hall_acc  \\\n",
       "0               0.500000              0.500                   0.5   \n",
       "1               0.500000              0.500                   0.5   \n",
       "2               0.500000              0.460                   0.5   \n",
       "3               0.500000              0.500                   0.5   \n",
       "4               0.500000              0.500                   0.5   \n",
       "5               0.500000              0.505                   0.5   \n",
       "6               0.500000              0.505                   0.5   \n",
       "7               0.500000              0.500                   0.5   \n",
       "8               0.500000              0.500                   0.5   \n",
       "9               0.500000              0.500                   0.5   \n",
       "10              0.500000              0.490                   0.5   \n",
       "11              0.500000              0.485                   0.5   \n",
       "12              0.500000              0.500                   0.5   \n",
       "13              0.500000              0.500                   0.5   \n",
       "14              0.500000              0.500                   0.5   \n",
       "15              0.500000              0.500                   0.5   \n",
       "16              0.505102              0.500                   0.5   \n",
       "17              0.500000              0.500                   0.5   \n",
       "18              0.500000              0.500                   0.5   \n",
       "19              0.500000              0.500                   0.5   \n",
       "20              0.500000              0.460                   0.5   \n",
       "21              0.500000              0.470                   0.5   \n",
       "22              0.500000              0.500                   0.5   \n",
       "23              0.500000              0.500                   0.5   \n",
       "24              0.500000              0.500                   0.5   \n",
       "\n",
       "    splice_site_hall_acc  splice_site_no_hall_acc  methylated_hall_acc  \\\n",
       "0               0.500000                 0.500000             0.500000   \n",
       "1               0.500000                 0.500000             0.500000   \n",
       "2               0.500000                 0.507143             0.500000   \n",
       "3               0.500000                 0.500000             0.500000   \n",
       "4               0.500000                 0.500000             0.500000   \n",
       "5               0.500000                 0.500000             0.500000   \n",
       "6               0.500000                 0.500000             0.505000   \n",
       "7               0.500000                 0.492857             0.500000   \n",
       "8               0.500000                 0.500000             0.500000   \n",
       "9               0.500000                 0.500000             0.500000   \n",
       "10              0.514286                 0.500000             0.515000   \n",
       "11              0.503597                 0.503597             0.510101   \n",
       "12              0.492857                 0.514286             0.500000   \n",
       "13              0.514286                 0.500000             0.500000   \n",
       "14              0.500000                 0.500000             0.500000   \n",
       "15              0.500000                 0.500000             0.500000   \n",
       "16              0.500000                 0.500000             0.505000   \n",
       "17              0.500000                 0.500000             0.500000   \n",
       "18              0.500000                 0.500000             0.500000   \n",
       "19              0.500000                 0.500000             0.500000   \n",
       "20              0.507143                 0.500000             0.485000   \n",
       "21              0.453237                 0.503597             0.545918   \n",
       "22              0.507143                 0.500000             0.500000   \n",
       "23              0.500000                 0.500000             0.500000   \n",
       "24              0.500000                 0.500000             0.500000   \n",
       "\n",
       "    methylated_no_hall_acc  protein_coding_hall_acc  \\\n",
       "0                 0.500000                 0.563830   \n",
       "1                 0.500000                 0.558511   \n",
       "2                 0.500000                 0.569149   \n",
       "3                 0.500000                 0.574468   \n",
       "4                 0.500000                 0.563830   \n",
       "5                 0.500000                 0.569149   \n",
       "6                 0.500000                 0.585106   \n",
       "7                 0.500000                 0.606383   \n",
       "8                 0.500000                 0.622340   \n",
       "9                 0.500000                 0.606383   \n",
       "10                0.500000                 0.526596   \n",
       "11                0.494949                 0.531915   \n",
       "12                0.500000                 0.526596   \n",
       "13                0.500000                 0.542553   \n",
       "14                0.500000                 0.531915   \n",
       "15                0.500000                 0.212766   \n",
       "16                0.500000                 0.234043   \n",
       "17                0.500000                 0.303191   \n",
       "18                0.500000                 0.372340   \n",
       "19                0.500000                 0.393617   \n",
       "20                0.500000                 0.382979   \n",
       "21                0.494898                 0.425532   \n",
       "22                0.500000                 0.335106   \n",
       "23                0.500000                 0.393617   \n",
       "24                0.500000                 0.446809   \n",
       "\n",
       "    protein_coding_no_hall_acc  overall_hall_acc  overall_no_hall_acc  \n",
       "0                     0.202128          0.512987             0.439394  \n",
       "1                     0.398936          0.511905             0.479437  \n",
       "2                     0.505319          0.505411             0.502165  \n",
       "3                     0.457447          0.515152             0.491342  \n",
       "4                     0.468085          0.512987             0.493506  \n",
       "5                     0.202128          0.515152             0.439394  \n",
       "6                     0.398936          0.519565             0.479348  \n",
       "7                     0.505319          0.521645             0.500000  \n",
       "8                     0.457447          0.524946             0.491323  \n",
       "9                     0.468085          0.521645             0.493506  \n",
       "10                    0.202128          0.510823             0.439394  \n",
       "11                    0.398936          0.503800             0.478827  \n",
       "12                    0.505319          0.504329             0.503247  \n",
       "13                    0.457447          0.510823             0.491342  \n",
       "14                    0.468085          0.506494             0.493506  \n",
       "15                    0.202128          0.441558             0.439394  \n",
       "16                    0.398936          0.445887             0.480519  \n",
       "17                    0.505319          0.459957             0.501082  \n",
       "18                    0.457447          0.474026             0.491342  \n",
       "19                    0.468085          0.478355             0.493506  \n",
       "20                    0.202128          0.464286             0.439394  \n",
       "21                    0.398936          0.486398             0.478781  \n",
       "22                    0.505319          0.466450             0.501082  \n",
       "23                    0.457447          0.478355             0.491342  \n",
       "24                    0.468085          0.488095             0.493506  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['enhancer', 'promoter', 'splice_site', 'methylated', 'protein_coding']\n",
    "summary_data = []\n",
    "\n",
    "for hallucination_model in MODELS:\n",
    "    for classification_model in MODELS:\n",
    "        model_combo = f\"{hallucination_model}-{classification_model}\"\n",
    "        combo_df = df[(df['hallucination_model'] == hallucination_model) & \n",
    "                       (df['classification_model'] == classification_model)]\n",
    "        \n",
    "        row_data = {\n",
    "            'hallucination_model': hallucination_model,\n",
    "            'classification_model': classification_model,\n",
    "            'combo': model_combo\n",
    "        }\n",
    "        \n",
    "        # Calculate accuracy for each feature\n",
    "        for feature in features:\n",
    "            feature_df = combo_df[combo_df['file_name'].str.contains(feature)]\n",
    "            \n",
    "            hall_acc = feature_df['hallucination_correct'].mean() if len(feature_df) > 0 else np.nan\n",
    "            no_hall_acc = feature_df['no_hallucination_correct'].mean() if len(feature_df) > 0 else np.nan\n",
    "            \n",
    "            row_data[f'{feature}_hall_acc'] = hall_acc\n",
    "            row_data[f'{feature}_no_hall_acc'] = no_hall_acc\n",
    "        \n",
    "        # Calculate overall accuracy\n",
    "        row_data['overall_hall_acc'] = combo_df['hallucination_correct'].mean()\n",
    "        row_data['overall_no_hall_acc'] = combo_df['no_hallucination_correct'].mean()\n",
    "        \n",
    "        summary_data.append(row_data)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Create pivot tables for easier comparison\n",
    "hall_pivot = pd.pivot_table(\n",
    "    summary_df, \n",
    "    values=['overall_hall_acc'] + [f'{f}_hall_acc' for f in features],\n",
    "    index='hallucination_model',\n",
    "    columns='classification_model'\n",
    ")\n",
    "\n",
    "no_hall_pivot = pd.pivot_table(\n",
    "    summary_df, \n",
    "    values=['overall_no_hall_acc'] + [f'{f}_no_hall_acc' for f in features],\n",
    "    index='hallucination_model',\n",
    "    columns='classification_model'\n",
    ")\n",
    "\n",
    "# Save summary results\n",
    "summary_df.to_csv(\"cross_model_OPEN_summary.csv\", index=False)\n",
    "hall_pivot.to_csv(\"cross_model_hall_OPEN_pivot.csv\")\n",
    "no_hall_pivot.to_csv(\"cross_model_OPEN_no_hall_pivot.csv\")\n",
    "\n",
    "# Generate difference analysis (how much hallucination affects accuracy)\n",
    "diff_data = []\n",
    "for _, row in summary_df.iterrows():\n",
    "    diff_row = {\n",
    "        'hallucination_model': row['hallucination_model'],\n",
    "        'classification_model': row['classification_model'],\n",
    "        'combo': row['combo'],\n",
    "        'overall_diff': row['overall_no_hall_acc'] - row['overall_hall_acc']\n",
    "    }\n",
    "    \n",
    "    for feature in features:\n",
    "        diff_row[f'{feature}_diff'] = row[f'{feature}_no_hall_acc'] - row[f'{feature}_hall_acc']\n",
    "    \n",
    "    diff_data.append(diff_row)\n",
    "\n",
    "diff_df = pd.DataFrame(diff_data)\n",
    "diff_pivot = pd.pivot_table(\n",
    "    diff_df,\n",
    "    values=['overall_diff'] + [f'{f}_diff' for f in features],\n",
    "    index='hallucination_model',\n",
    "    columns='classification_model'\n",
    ")\n",
    "\n",
    "diff_df.to_csv(\"cross_model_OPEN_diff.csv\", index=False)\n",
    "diff_pivot.to_csv(\"cross_model_OPEN_diff_pivot.csv\")\n",
    "\n",
    "print(\"Analysis complete. Results saved to CSV files.\")\n",
    "\n",
    "# Return the summary dataframe for quick inspection\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
