{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "load_dotenv()\n",
    "nvda = os.getenv(\"nvda\")\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = nvda\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored enhancer with 98 genes.\n",
      "Stored methylated with 100 genes.\n",
      "Stored non_enhancer with 98 genes.\n",
      "Stored non_methylated with 100 genes.\n",
      "Stored non_promoter with 100 genes.\n",
      "Stored non_protein_coding with 88 genes.\n",
      "Stored non_splice_site with 70 genes.\n",
      "Stored promoter with 100 genes.\n",
      "Stored protein_coding with 100 genes.\n",
      "Stored splice_site with 70 genes.\n"
     ]
    }
   ],
   "source": [
    "fasta_dir = \"sequences\"\n",
    "\n",
    "# Mapping of base categories to questions\n",
    "questions = {\n",
    "    \"protein_coding\": \"Does this nucleotide sequence encode a protein? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"enhancer\": \"Does this nucleotide sequence function as an enhancer in gene regulation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"promoter\": \"Does this nucleotide sequence act as a promoter for transcription initiation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"splice_site\": \"Does this nucleotide sequence contain a splice site for RNA processing? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\",\n",
    "    \"methylated\": \"Is this nucleotide sequence methylated as part of epigenetic regulation? Only answer Yes or No. You must start your answer with 'Yes' or 'No'.\"\n",
    "}\n",
    "\n",
    "# Dictionary to hold sequence data\n",
    "sequence_arrays = {}\n",
    "\n",
    "# Loop through all FASTA files in the directory\n",
    "for file in os.listdir(fasta_dir):\n",
    "    if file.endswith(\".fasta\"):  # Process only FASTA files\n",
    "        file_path = os.path.join(fasta_dir, file)\n",
    "        var_name = os.path.splitext(file)[0]  # Use file name (without extension) as key\n",
    "\n",
    "        # Determine base category\n",
    "        if var_name.startswith(\"non_\"):\n",
    "            base_category = var_name[4:]  # Remove \"non_\" prefix\n",
    "        else:\n",
    "            base_category = var_name\n",
    "        question = questions[base_category]  # Get the corresponding question\n",
    "\n",
    "        # Read the FASTA file and create a list of dictionaries\n",
    "        gene_dicts = []\n",
    "        for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "            gene_dict = {\n",
    "                \"file_name\": var_name,\n",
    "                \"gene\": str(record.seq),\n",
    "                \"question\": question,  # Add the question key\n",
    "            }\n",
    "            gene_dicts.append(gene_dict)\n",
    "        \n",
    "        # Store the list of dictionaries in the dictionary\n",
    "        sequence_arrays[var_name] = gene_dicts\n",
    "\n",
    "        print(f\"Stored {var_name} with {len(gene_dicts)} genes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hallucination(gene_dict, model):\n",
    "    response = client.chat.completions.create(\n",
    "            model= model,  #Use the model specified in the constructor\n",
    "\n",
    "            messages=\n",
    "            [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} Describe the gene in natural language:\"}\n",
    "        ],  #The conversation context to send to the API\n",
    "\n",
    "\n",
    "            max_tokens=256,  #Maximum length of the response\n",
    "\n",
    "            temperature=0.6  #Controls randomness/creativity of the response\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification(gene_dict, model):\n",
    "    response = client.chat.completions.create(\n",
    "            model = model,  #Use the model specified in the constructor\n",
    "\n",
    "            messages=\n",
    "            [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} {gene_dict['question']}\"}\n",
    "        ],  #The conversation context to send to the API\n",
    "\n",
    "\n",
    "            max_tokens=256,  #Maximum length of the response\n",
    "\n",
    "            temperature=0.6  #Controls randomness/creativity of the response\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hallucination_classification(gene_dict, model):\n",
    "    response = client.chat.completions.create(\n",
    "            model = model,  #Use the model specified in the constructor\n",
    "\n",
    "            messages=\n",
    "            [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in genomics.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{gene_dict['gene']} {gene_dict['hallucination']} {gene_dict['question']}\"}\n",
    "        ],  #The conversation context to send to the API\n",
    "\n",
    "\n",
    "            max_tokens=256,  #Maximum length of the response\n",
    "\n",
    "            temperature=0.6  #Controls randomness/creativity of the response\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model [7/6]: gemma-2-27b-it:   0%|          | 0/10 [39:33<?, ?it/s]\n",
      "                                                                                  \n",
      "                                                                                        \n",
      "                                                                                      \n",
      "                                                                                            \n",
      "                                                                                          \n",
      "                                                                                            \n",
      "                                                                                         \n",
      "                                                                                      \n",
      "                                                                                            \n",
      "                                                                                      \n",
      "Model [1/6]: llama3-8b-instruct: 100%|██████████| 10/10 [29:52<00:00, 179.28s/it]\n",
      "Model [2/6]: llama-3.1-8b-instruct: 100%|██████████| 10/10 [1:02:32<00:00, 375.26s/it]\n",
      "Model [3/6]: llama-3.3-70b-instruct: 100%|██████████| 10/10 [1:13:38<00:00, 441.83s/it]\n",
      "Model [4/6]: falcon3-7b-instruct: 100%|██████████| 10/10 [1:03:08<00:00, 378.84s/it]\n",
      "Model [5/6]: qwen2.5-7b-instruct: 100%|██████████| 10/10 [1:43:09<00:00, 618.99s/it]\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "MODELS = [\n",
    "    \"meta/llama3-8b-instruct\",\n",
    "    \"meta/llama-3.1-8b-instruct\",\n",
    "    \"meta/llama-3.3-70b-instruct\",\n",
    "    \"tiiuae/falcon3-7b-instruct\",\n",
    "    \"qwen/qwen2.5-7b-instruct\",\n",
    "    ]\n",
    "\n",
    "for model_idx, model in enumerate(MODELS):\n",
    "    model_progress = tqdm(total=len(sequence_arrays), desc=f\"Model [{model_idx+1}/6]: {model.split('/')[-1]}\")\n",
    "    \n",
    "    for file_idx, (file, sequences) in enumerate(sequence_arrays.items()):\n",
    "        file_progress = tqdm(total=len(sequences), desc=f\"File [{file_idx+1}/{len(sequence_arrays)}]: {file}\", leave=False)\n",
    "        \n",
    "        for gene_idx, gene in enumerate(sequences):\n",
    "            file_progress.set_postfix_str(f\"Gene {gene_idx+1}/{len(sequences)}\")\n",
    "            \n",
    "            result = gene.copy()\n",
    "            result['model'] = model\n",
    "            \n",
    "            try:\n",
    "                result['hallucination'] = generate_hallucination(result, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating hallucination for {file}, gene {gene_idx+1}: {str(e)}\")\n",
    "                result['hallucination'] = None\n",
    "            \n",
    "            try:\n",
    "                result['hallucination_classification'] = generate_hallucination_classification(result, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating hallucination classification for {file}, gene {gene_idx+1}: {str(e)}\")\n",
    "                result['hallucination_classification'] = None\n",
    "            \n",
    "            try:\n",
    "                result['classification'] = generate_classification(result, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating classification for {file}, gene {gene_idx+1}: {str(e)}\")\n",
    "                result['classification'] = None\n",
    "            \n",
    "            all_results.append(result)\n",
    "            \n",
    "            file_progress.update(1)\n",
    "        \n",
    "        file_progress.close()\n",
    "        model_progress.update(1)\n",
    "    \n",
    "    model_progress.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Add expected correct answer column\n",
    "df['correct'] = df['file_name'].str.contains(\"non\", case=True, na=False).map({True: \"No\", False: \"Yes\"})\n",
    "\n",
    "# Clean the classification outputs\n",
    "df['hallucination_classification'] = df['hallucination_classification'].str.replace(\".\", \"\", regex=False)\n",
    "df['classification'] = df['classification'].str.replace(\".\", \"\", regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'Yes' 'Yes' ... 'No' 'No' 'No']\n",
      "['No' 'No' 'No' ... 'No' 'No' 'No']\n"
     ]
    }
   ],
   "source": [
    "df['hallucination_classification'] = df['hallucination_classification'].apply(\n",
    "    lambda x: 'Yes' if isinstance(x, str) and x.split()[0].lower()[:3] == 'yes' else\n",
    "              'No' if isinstance(x, str) and x.split()[0].lower()[:2] == 'no' else np.nan\n",
    ")\n",
    "print(df['hallucination_classification'].values)\n",
    "\n",
    "df['classification'] = df['classification'].apply(\n",
    "    lambda x: 'Yes' if isinstance(x, str) and x.split()[0].lower()[:3] == 'yes' else\n",
    "              'No' if isinstance(x, str) and x.split()[0].lower()[:2] == 'no' else np.nan\n",
    ")\n",
    "print(df['classification'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "meta/llama-3.1-8b-instruct    4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['hallucination_classification'].isna()]['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['classification'].isna()]['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df['hallucination_correct'] = df['hallucination_classification'] == df['correct']\n",
    "df['no_hallucination_correct'] = df['classification'] == df['correct']\n",
    "df.to_csv(\"trail_1_open.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>enhancer</th>\n",
       "      <th>promoter</th>\n",
       "      <th>splice_site</th>\n",
       "      <th>methylated</th>\n",
       "      <th>protein_coding</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>hallucination_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">meta/llama-3.1-8b-instruct</th>\n",
       "      <th>Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.5160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.4798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">meta/llama-3.3-70b-instruct</th>\n",
       "      <th>Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.4813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.4978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">meta/llama3-8b-instruct</th>\n",
       "      <th>Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.5128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">qwen/qwen2.5-7b-instruct</th>\n",
       "      <th>Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0.4883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.4936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">tiiuae/falcon3-7b-instruct</th>\n",
       "      <th>Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.4745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Hallucination</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.4915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature                                           enhancer  promoter  \\\n",
       "model                       hallucination_status                       \n",
       "meta/llama-3.1-8b-instruct  Hallucination              0.5       0.5   \n",
       "                            No Hallucination           0.5       0.5   \n",
       "meta/llama-3.3-70b-instruct Hallucination              0.5       0.5   \n",
       "                            No Hallucination           0.5       0.5   \n",
       "meta/llama3-8b-instruct     Hallucination              0.5       0.5   \n",
       "                            No Hallucination           0.5       0.5   \n",
       "qwen/qwen2.5-7b-instruct    Hallucination              0.5       0.5   \n",
       "                            No Hallucination           0.5       0.5   \n",
       "tiiuae/falcon3-7b-instruct  Hallucination              0.5       0.5   \n",
       "                            No Hallucination           0.5       0.5   \n",
       "\n",
       "feature                                           splice_site  methylated  \\\n",
       "model                       hallucination_status                            \n",
       "meta/llama-3.1-8b-instruct  Hallucination            0.500000       0.495   \n",
       "                            No Hallucination         0.500000       0.500   \n",
       "meta/llama-3.3-70b-instruct Hallucination            0.485714       0.490   \n",
       "                            No Hallucination         0.478571       0.500   \n",
       "meta/llama3-8b-instruct     Hallucination            0.500000       0.500   \n",
       "                            No Hallucination         0.500000       0.500   \n",
       "qwen/qwen2.5-7b-instruct    Hallucination            0.500000       0.500   \n",
       "                            No Hallucination         0.500000       0.500   \n",
       "tiiuae/falcon3-7b-instruct  Hallucination            0.500000       0.500   \n",
       "                            No Hallucination         0.500000       0.500   \n",
       "\n",
       "feature                                           protein_coding     AVG  \n",
       "model                       hallucination_status                          \n",
       "meta/llama-3.1-8b-instruct  Hallucination               0.585106  0.5160  \n",
       "                            No Hallucination            0.398936  0.4798  \n",
       "meta/llama-3.3-70b-instruct Hallucination               0.430851  0.4813  \n",
       "                            No Hallucination            0.510638  0.4978  \n",
       "meta/llama3-8b-instruct     Hallucination               0.563830  0.5128  \n",
       "                            No Hallucination            0.202128  0.4404  \n",
       "qwen/qwen2.5-7b-instruct    Hallucination               0.441489  0.4883  \n",
       "                            No Hallucination            0.468085  0.4936  \n",
       "tiiuae/falcon3-7b-instruct  Hallucination               0.372340  0.4745  \n",
       "                            No Hallucination            0.457447  0.4915  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancer_hallucination_correct = df[df['file_name'].str.contains(\"enhancer\")].groupby('model')['hallucination_correct'].mean()\n",
    "enhancer_no_hallucination_correct = df[df['file_name'].str.contains(\"enhancer\")].groupby('model')['no_hallucination_correct'].mean()\n",
    "\n",
    "promoter_hallucination_correct = df[df['file_name'].str.contains(\"promoter\")].groupby('model')['hallucination_correct'].mean()\n",
    "promoter_no_hallucination_correct = df[df['file_name'].str.contains(\"promoter\")].groupby('model')['no_hallucination_correct'].mean() \n",
    "\n",
    "splice_site_hallucination_correct = df[df['file_name'].str.contains(\"splice_site\")].groupby('model')['hallucination_correct'].mean()     \n",
    "splice_site_no_hallucination_correct = df[df['file_name'].str.contains(\"splice_site\")].groupby('model')['no_hallucination_correct'].mean()\n",
    "\n",
    "methylated_hallucination_correct = df[df['file_name'].str.contains(\"methylated\")].groupby('model')['hallucination_correct'].mean()   \n",
    "methylated_no_hallucination_correct = df[df['file_name'].str.contains(\"methylated\")].groupby('model')['no_hallucination_correct'].mean() \n",
    "\n",
    "protein_coding_hallucination_correct = df[df['file_name'].str.contains(\"protein_coding\")].groupby('model')['hallucination_correct'].mean()   \n",
    "protein_coding_no_hallucination_correct = df[df['file_name'].str.contains(\"protein_coding\")].groupby('model')['no_hallucination_correct'].mean()\n",
    "\n",
    "data = {\n",
    "    'enhancer_hallucination_correct': enhancer_hallucination_correct,\n",
    "    'enhancer_no_hallucination_correct': enhancer_no_hallucination_correct,\n",
    "    'promoter_hallucination_correct': promoter_hallucination_correct,\n",
    "    'promoter_no_hallucination_correct': promoter_no_hallucination_correct,\n",
    "    'splice_site_hallucination_correct': splice_site_hallucination_correct,\n",
    "    'splice_site_no_hallucination_correct': splice_site_no_hallucination_correct,\n",
    "    'methylated_hallucination_correct': methylated_hallucination_correct,\n",
    "    'methylated_no_hallucination_correct': methylated_no_hallucination_correct,\n",
    "    'protein_coding_hallucination_correct': protein_coding_hallucination_correct,\n",
    "    'protein_coding_no_hallucination_correct': protein_coding_no_hallucination_correct\n",
    "}\n",
    "\n",
    "pivot_data = []\n",
    "\n",
    "for feature in ['enhancer', 'promoter', 'splice_site', 'methylated', 'protein_coding']:\n",
    "    hall_series = data[f'{feature}_hallucination_correct']\n",
    "\n",
    "    no_hall_series = data[f'{feature}_no_hallucination_correct']\n",
    "\n",
    "    for model in hall_series.index:\n",
    "        pivot_data.append({\n",
    "            'model': model,\n",
    "            'hallucination_status': 'Hallucination',\n",
    "            'feature': feature,\n",
    "            'correct_count': hall_series[model]\n",
    "        })\n",
    "\n",
    "        pivot_data.append({\n",
    "            'model': model,\n",
    "            'hallucination_status': 'No Hallucination',\n",
    "            'feature': feature,\n",
    "            'correct_count': no_hall_series[model]\n",
    "        })\n",
    "\n",
    "long_df = pd.DataFrame(pivot_data)\n",
    "\n",
    "pivot_df = long_df.pivot_table(\n",
    "    index=['model', 'hallucination_status'],\n",
    "    columns='feature',\n",
    "    values='correct_count'\n",
    ")\n",
    "\n",
    "feature_order = ['enhancer', 'promoter', 'splice_site', 'methylated', 'protein_coding']\n",
    "pivot_df = pivot_df[feature_order]\n",
    "\n",
    "pivot_df['AVG'] = pivot_df.mean(axis=1)\n",
    "\n",
    "pivot_df['AVG'] = pivot_df['AVG'].round(4) \n",
    "\n",
    "pivot_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
